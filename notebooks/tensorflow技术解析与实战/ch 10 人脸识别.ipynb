{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 人脸识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1 人脸识别流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1.1 人脸图像采集及检测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（1）对要检测的目标对象进行概率统计，从而得到待检测对象的一些特征，建立起目标检测模型；  \n",
    "（2）用得到的模型来匹配输入的图像，如果有匹配则输出匹配的区域，没有就什么也不做。  \n",
    "模版匹配，Adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.1.2 人脸图像预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "缩放、拉伸、光线补偿、灰度变换、直方图均衡化、规范化、几何校正、过滤以及锐化等图像预处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1.3 人脸图像特征提取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1.4 人脸图像匹配与识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "确认和辨认"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2 人脸识别的分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2.1 人脸检测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2.2 人脸关键点检测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "级联形回归(cascaded shape regression, CSR) DeepID 网络结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2.3 人脸验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2.4 人脸属性检测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.3 人脸检测"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 下载代码\n",
    "git clone --recursive https://github.com/davidsandberg/facenet.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.1 LFW数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://vis-www.cs.umass.edu/lfw/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.2 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "facenet/align/dlign_dataset_mtcnn.py"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for N in {1..4}; do python src/align/align_dataset_mtcnn.py /home/tfb/dev/github/davidsandberg/facenet/datasets/lfw/ /home/tfb/dev/github/davidsandberg/facenet/datasets/lfw/lfw_mtcnnpy_160 --image_size 160 --margin 32 --random_order --gpu_memory_fraction 0.25 & doneexport PYTHONPATH=$YOURHOME/facenet/src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预训练模型 https://drive.google.com/file/d/0B5MzpY9kBtDVTGZjcWkzT3pldDA/view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.3 进行检测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进入 facenet目录，运行脚本"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "python src/validate_on_lfw.py datasets/lfw/lfw_mtcnnpy_160 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "valiate_on_lfw.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(args):\n",
    "  \n",
    "    with tf.Graph().as_default():\n",
    "      \n",
    "        with tf.Session() as sess:\n",
    "            \n",
    "            # 读入之前的pairs.txt 文件\n",
    "            pairs = lfw.read_pairs(os.path.expanduser(args.lfw_pairs))\n",
    "\n",
    "            # Get the paths for the corresponding images\n",
    "            paths, actual_issame = lfw.get_paths(os.path.expanduser(args.lfw_dir), pairs, args.lfw_file_ext)\n",
    "\n",
    "            # 加载模型\n",
    "            facenet.load_model(args.model)\n",
    "            \n",
    "            # Get input and output tensors\n",
    "            images_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "            embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "            phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "            \n",
    "            #image_size = images_placeholder.get_shape()[1]  # For some reason this doesn't work for frozen graphs\n",
    "            image_size = args.image_size\n",
    "            embedding_size = embeddings.get_shape()[1]\n",
    "        \n",
    "            # Run forward pass to calculate embeddings\n",
    "            print('Runnning forward pass on LFW images')\n",
    "            batch_size = args.lfw_batch_size\n",
    "            nrof_images = len(paths)\n",
    "            nrof_batches = int(math.ceil(1.0*nrof_images / batch_size))\n",
    "            emb_array = np.zeros((nrof_images, embedding_size))\n",
    "            for i in range(nrof_batches):\n",
    "                start_index = i*batch_size\n",
    "                end_index = min((i+1)*batch_size, nrof_images)\n",
    "                paths_batch = paths[start_index:end_index]\n",
    "                images = facenet.load_data(paths_batch, False, False, image_size)\n",
    "                feed_dict = { images_placeholder:images, phase_train_placeholder:False }\n",
    "                emb_array[start_index:end_index,:] = sess.run(embeddings, feed_dict=feed_dict)\n",
    "        \n",
    "            tpr, fpr, accuracy, val, val_std, far = lfw.evaluate(emb_array, \n",
    "                actual_issame, nrof_folds=args.lfw_nrof_folds)\n",
    "\n",
    "            print('Accuracy: %1.3f+-%1.3f' % (np.mean(accuracy), np.std(accuracy)))\n",
    "            print('Validation rate: %2.5f+-%2.5f @ FAR=%2.5f' % (val, val_std, far))\n",
    "\n",
    "            auc = metrics.auc(fpr, tpr)\n",
    "            print('Area Under Curve (AUC): %1.3f' % auc)\n",
    "            eer = brentq(lambda x: 1. - x - interpolate.interp1d(fpr, tpr)(x), 0., 1.)\n",
    "            print('Equal Error Rate (EER): %1.3f' % eer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.4 性别和年龄识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adience 数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4.1 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将数据处理成TFRecords的格式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4.2 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def levi_hassner(nlabels, image, pkeep, is_training):\n",
    "    weights_decay = 0.0005\n",
    "    weights_regularizer = tf.contrib.layers.l2_regularizer(weight_decay)\n",
    "    with tf.variable_scope(\"LeviHassner\", \"LeviHassner\", [images]) as scope:\n",
    "\n",
    "        with tf.contrib.slim.arg_scope(\n",
    "                [convolution2d, fully_connected],\n",
    "                weights_regularizer=weights_regularizer,\n",
    "                biases_initializer=tf.constant_initializer(1.),\n",
    "                weights_initializer=tf.random_normal_initializer(stddev=0.005),\n",
    "                trainable=True):\n",
    "            with tf.contrib.slim.arg_scope(\n",
    "                    [convolution2d],\n",
    "                    weights_initializer=tf.random_normal_initializer(stddev=0.01)):\n",
    "\n",
    "                conv1 = convolution2d(images, 96, [7,7], [4, 4], padding='VALID', biases_initializer=tf.constant_initializer(0.), scope='conv1')\n",
    "                pool1 = max_pool2d(conv1, 3, 2, padding='VALID', scope='pool1')\n",
    "                norm1 = tf.nn.local_response_normalization(pool1, 5, alpha=0.0001, beta=0.75, name='norm1')\n",
    "                conv2 = convolution2d(norm1, 256, [5, 5], [1, 1], padding='SAME', scope='conv2') \n",
    "                pool2 = max_pool2d(conv2, 3, 2, padding='VALID', scope='pool2')\n",
    "                norm2 = tf.nn.local_response_normalization(pool2, 5, alpha=0.0001, beta=0.75, name='norm2')\n",
    "                conv3 = convolution2d(norm2, 384, [3, 3], [1, 1], biases_initializer=tf.constant_initializer(0.), padding='SAME', scope='conv3')\n",
    "                pool3 = max_pool2d(conv3, 3, 2, padding='VALID', scope='pool3')\n",
    "                flat = tf.reshape(pool3, [-1, 384*6*6], name='reshape')\n",
    "                full1 = fully_connected(flat, 512, scope='full1')\n",
    "                drop1 = tf.nn.dropout(full1, pkeep, name='drop1')\n",
    "                full2 = fully_connected(drop1, 512, scope='full2')\n",
    "                drop2 = tf.nn.dropout(full2, pkeep, name='drop2')\n",
    "\n",
    "    with tf.variable_scope('output') as scope:\n",
    "        \n",
    "        weights = tf.Variable(tf.random_normal([512, nlabels], mean=0.0, stddev=0.01), name='weights')\n",
    "        biases = tf.Variable(tf.constant(0.0, shape=[nlabels], dtype=tf.float32), name='biases')\n",
    "        output = tf.add(tf.matmul(drop2, weights), biases, name=scope.name)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4.3 训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "github.com/dpressel/rude-carnie/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(argv=None):\n",
    "    with tf.Graph().as_default():\n",
    "\n",
    "        model_fn = select_model(FLAGS.model_type)\n",
    "        # Open the metadata file and figure out nlabels, and size of epoch\n",
    "        input_file = os.path.join(FLAGS.train_dir, 'md.json')\n",
    "        print(input_file)\n",
    "        with open(input_file, 'r') as f:\n",
    "            md = json.load(f)\n",
    "\n",
    "        images, labels, _ = distorted_inputs(FLAGS.train_dir, FLAGS.batch_size, FLAGS.image_size, FLAGS.num_preprocess_threads)\n",
    "        logits = model_fn(md['nlabels'], images, 1-FLAGS.pdrop, True)\n",
    "        total_loss = loss(logits, labels)\n",
    "\n",
    "        train_op = optimizer(FLAGS.optim, FLAGS.eta, total_loss, FLAGS.steps_per_decay, FLAGS.eta_decay_rate)\n",
    "        saver = tf.train.Saver(tf.global_variables())\n",
    "        summary_op = tf.summary.merge_all()\n",
    "\n",
    "        sess = tf.Session(config=tf.ConfigProto(\n",
    "            log_device_placement=FLAGS.log_device_placement))\n",
    "\n",
    "        tf.global_variables_initializer().run(session=sess)\n",
    "\n",
    "        # This is total hackland, it only works to fine-tune iv3\n",
    "        if FLAGS.pre_model:\n",
    "            inception_variables = tf.get_collection(\n",
    "                tf.GraphKeys.VARIABLES, scope=\"InceptionV3\")\n",
    "            restorer = tf.train.Saver(inception_variables)\n",
    "            restorer.restore(sess, FLAGS.pre_model)\n",
    "\n",
    "        if FLAGS.pre_checkpoint_path:\n",
    "            if tf.gfile.Exists(FLAGS.pre_checkpoint_path) is True:\n",
    "                print('Trying to restore checkpoint from %s' % FLAGS.pre_checkpoint_path)\n",
    "                restorer = tf.train.Saver()\n",
    "                tf.train.latest_checkpoint(FLAGS.pre_checkpoint_path)\n",
    "                print('%s: Pre-trained model restored from %s' %\n",
    "                      (datetime.now(), FLAGS.pre_checkpoint_path))\n",
    "\n",
    "\n",
    "        run_dir = '%s/run-%d' % (FLAGS.train_dir, os.getpid())\n",
    "\n",
    "        checkpoint_path = '%s/%s' % (run_dir, FLAGS.checkpoint)\n",
    "        if tf.gfile.Exists(run_dir) is False:\n",
    "            print('Creating %s' % run_dir)\n",
    "            tf.gfile.MakeDirs(run_dir)\n",
    "\n",
    "        tf.train.write_graph(sess.graph_def, run_dir, 'model.pb', as_text=True)\n",
    "\n",
    "        tf.train.start_queue_runners(sess=sess)\n",
    "\n",
    "\n",
    "        summary_writer = tf.summary.FileWriter(run_dir, sess.graph)\n",
    "        steps_per_train_epoch = int(md['train_counts'] / FLAGS.batch_size)\n",
    "        num_steps = FLAGS.max_steps if FLAGS.epochs < 1 else FLAGS.epochs * steps_per_train_epoch\n",
    "        print('Requested number of steps [%d]' % num_steps)\n",
    "\n",
    "        \n",
    "        for step in xrange(num_steps):\n",
    "            start_time = time.time()\n",
    "            _, loss_value = sess.run([train_op, total_loss])\n",
    "            duration = time.time() - start_time\n",
    "\n",
    "            assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\n",
    "\n",
    "            if step % 10 == 0:\n",
    "                num_examples_per_step = FLAGS.batch_size\n",
    "                examples_per_sec = num_examples_per_step / duration\n",
    "                sec_per_batch = float(duration)\n",
    "                \n",
    "                format_str = ('%s: step %d, loss = %.3f (%.1f examples/sec; %.3f ' 'sec/batch)')\n",
    "                print(format_str % (datetime.now(), step, loss_value,\n",
    "                                    examples_per_sec, sec_per_batch))\n",
    "\n",
    "            # Loss only actually evaluated every 100 steps?\n",
    "            if step % 100 == 0:\n",
    "                summary_str = sess.run(summary_op)\n",
    "                summary_writer.add_summary(summary_str, step)\n",
    "                \n",
    "            if step % 1000 == 0 or (step + 1) == num_steps:\n",
    "                saver.save(sess, checkpoint_path, global_step=step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4.4 验证模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
