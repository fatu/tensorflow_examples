{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 tensorflow的高级框架"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 TFLearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.1 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.normalization import local_response_normalization\n",
    "from tflearn.layers.estimator import regression\n",
    "import tflearn.datasets.oxflower17 as oxflower17\n",
    "X, Y = oxflower17.load_data(one_hot=True, resize_pics=(227, 227))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.2 构建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 构建AlexNet网络\n",
    "network = input_data(shape=[None, 227, 227, 3])\n",
    "network = conv_2d(network, 96, 11, strides=4, activation='relu')\n",
    "network = max_pool_2d(network, 3, strides=2)\n",
    "network = local_response_normalization(network)\n",
    "network = conv_2d(network, 256, 5, activation='relu')\n",
    "network = max_pool_2d(network, 3, strides=2)\n",
    "network = local_response_normalization(network)\n",
    "network = conv_2d(network, 384, 3, activation='relu')\n",
    "network = conv_2d(network, 384, 3, activation='relu')\n",
    "network = conv_2d(network, 256, 3, activation='relu')\n",
    "network = max_pool_2d(network, 3, strides=2)\n",
    "network = local_response_normalization(network)\n",
    "network = fully_connected(network, 4096, activation='tanh')\n",
    "network = dropout(network, 0.5)\n",
    "network = fully_connected(network, 4096, activation='tanh')\n",
    "network = dropout(network, 0.5)\n",
    "network = fully_connected(network, 17, activation='softmax')\n",
    "network = regression(network, optimizer='momentum', loss='categorical_crossentropy', learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.3 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 21  | total loss: \u001b[1m\u001b[32m2.82188\u001b[0m\u001b[0m | time: 3.841s\n",
      "\u001b[2K\r",
      "| Momentum | epoch: 002 | loss: 2.82188 - acc: 0.1085 -- iter: 0064/1224\n"
     ]
    }
   ],
   "source": [
    "model = tflearn.DNN(network, checkpoint_path='model_alexnet', max_checkpoints=1, tensorboard_verbose=2)\n",
    "model.fit(X, Y, n_epoch=1000, validation_set=0.1, shuffle=True,\n",
    "          show_metric=True, batch_size=64, snapshot_step=200,\n",
    "          snapshot_epoch=False, run_id='alexnet_oxflowers17')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 7.2 Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.1 Keras 的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fatu/anaconda/envs/tensorflowpy2/lib/python2.7/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=64, input_dim=100)`\n",
      "  \"\"\"\n",
      "/Users/fatu/anaconda/envs/tensorflowpy2/lib/python2.7/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=10)`\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "model = Sequential()\n",
    "model.add(Dense(output_dim=64, input_dim=100))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(output_dim=10))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Keras 的使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. 实现卷积神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras import utils as np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入图片维度\n",
    "img_rows, img_cols = 28, 28\n",
    "# 卷积滤镜的个数\n",
    "nb_filters = 32\n",
    "# 最大池化，池化核大小\n",
    "pool_size = (2, 2)\n",
    "# 卷积核大小\n",
    "kernel_size = (3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# 将类向量转换为二进制类矩阵\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用2个卷积层、1个池化层和2个全连接层来构建\n",
    "model = Sequential()\n",
    "model.add(Conv2D(nb_filters, kernel_size=kernel_size,\n",
    "                       activation='relu',\n",
    "                       input_shape=input_shape))\n",
    "model.add(Conv2D(nb_filters, kernel_size,activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用model.compile()函数编译模型，采用多分类的损失函数，用Adadelta算法做优化方法\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 3s - loss: 0.3895 - acc: 0.8812 - val_loss: 0.0995 - val_acc: 0.9694\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 3s - loss: 0.1465 - acc: 0.9568 - val_loss: 0.0673 - val_acc: 0.9788\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 3s - loss: 0.1111 - acc: 0.9674 - val_loss: 0.0541 - val_acc: 0.9819\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 3s - loss: 0.0929 - acc: 0.9731 - val_loss: 0.0459 - val_acc: 0.9851\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 3s - loss: 0.0782 - acc: 0.9766 - val_loss: 0.0432 - val_acc: 0.9847\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 3s - loss: 0.0717 - acc: 0.9788 - val_loss: 0.0393 - val_acc: 0.9865\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 3s - loss: 0.0650 - acc: 0.9815 - val_loss: 0.0366 - val_acc: 0.9882\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 3s - loss: 0.0611 - acc: 0.9819 - val_loss: 0.0341 - val_acc: 0.9886\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 3s - loss: 0.0547 - acc: 0.9836 - val_loss: 0.0335 - val_acc: 0.9891\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 3s - loss: 0.0527 - acc: 0.9847 - val_loss: 0.0306 - val_acc: 0.9907\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 3s - loss: 0.0494 - acc: 0.9855 - val_loss: 0.0310 - val_acc: 0.9902\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 3s - loss: 0.0477 - acc: 0.9855 - val_loss: 0.0300 - val_acc: 0.9898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdbec088d50>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 然后，开始用model.fit()函数训练模型，输入训练集和测试数据，以及batch_size和epoch参数\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0299538767546\n",
      "Test accuracy: 0.9898\n"
     ]
    }
   ],
   "source": [
    "# 最后用model.evaluat()函数来评估模型\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 模型的加载及保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import save_model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sequential_model_saving():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(2, input_shape=(3,)))\n",
    "    model.add(RepeatVector(3))\n",
    "    model.add(TimeDistributed(Dense(3)))\n",
    "    model.compile(loss=losses.MSE,\n",
    "                  optimizer=optimizers.RMSprop(lr=0.0001),\n",
    "                  metrics=[metrics.categorical_accuracy],\n",
    "                  sample_weight_mode='temporal')\n",
    "    x = np.random.random((1, 3))\n",
    "    y = np.random.random((1, 3, 3))\n",
    "    model.train_on_batch(x, y)\n",
    "\n",
    "    out = model.predict(x)\n",
    "    _, fname = tempfile.mkstemp('.h5')\n",
    "    save_model(model, fname)\n",
    "\n",
    "    new_model = load_model(fname)\n",
    "    os.remove(fname)\n",
    "\n",
    "    out2 = new_model.predict(x)\n",
    "    assert_allclose(out, out2, atol=1e-05)\n",
    "\n",
    "    # test that new updates are the same with both models\n",
    "    x = np.random.random((1, 3))\n",
    "    y = np.random.random((1, 3, 3))\n",
    "    model.train_on_batch(x, y)\n",
    "    new_model.train_on_batch(x, y)\n",
    "    out = model.predict(x)\n",
    "    out2 = new_model.predict(x)\n",
    "    assert_allclose(out, out2, atol=1e-05)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "如果只是希望保存模型的结构，而不包含其权重及训练的配置(损失函数、优化器),可以使用下面的代码将模型序列化成json或yaml文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = model.to_json()\n",
    "json_string = model.to_yaml()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存完成后，还可以手动编辑，并且使用如下语句进行加载："
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from keras.models import model_from_json\n",
    "model = model_from_json(json_string)\n",
    "model = model_from_yaml(yaml_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果仅需要保存模型权重，不包含模型结构，可以使用save_weights和load_weights语句来保存和加载:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('my_model_weights.h5')\n",
    "model.load_weights('my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
