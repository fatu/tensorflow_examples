{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 stacking 的基本思想\n",
    "\n",
    "\n",
    "stacking 就是将一系列模型（也称基模型）的输出结果作为新特征输入到其他模型，这种方法由于实现了模型的层叠，即第一层的模型输出作为第二层模型的输入，第二层模型的输出作为第三层模型的输入，依次类推，最后一层模型输出的结果作为最终结果。本文会以两层的 stacking 为例进行说明。\n",
    "\n",
    "\n",
    "\n",
    "stacking 的思想也很好理解，这里以论文审稿为例，首先是三个审稿人分别对论文进行审稿，然后分别返回审稿意见给总编辑，总编辑会结合审稿人的意见给出最终的判断，即是否录用。\n",
    "\n",
    "\n",
    "\n",
    "对应于stacking，这里的三个审稿人就是第一层的模型，其输出（审稿人意见）会作为第二层模型（总编辑）的输入，然后第二层模型会给出最终的结果。\n",
    "\n",
    "\n",
    "\n",
    "stacking 的思想很好理解，但是在实现时需要注意不能有泄漏（leak）的情况，也就是说对于训练样本中的每一条数据，基模型输出其结果时并不能用这条数据来训练。\n",
    "\n",
    "\n",
    "\n",
    "否则就是用这条数据来训练，同时用这条数据来测试，这样会造成最终预测时的过拟合现象，即经过stacking后在训练集上进行验证时效果很好，但是在测试集上效果很差。\n",
    "\n",
    "\n",
    "\n",
    "为了解决这个泄漏的问题，需要通过 K-Fold 方法分别输出各部分样本的结果，这里以 5-Fold 为例，具体步骤如下\n",
    "\n",
    "\n",
    "\n",
    "(1) 将数据划分为 5 部分，每次用其中 1 部分做验证集，其余 4 部分做训练集，则共可训练出 5 个模型\n",
    "\n",
    "(2) 对于训练集，每次训练出一个模型时，通过该模型对没有用来训练的验证集进行预测，将预测结果作为验证集对应的样本的第二层输入，则依次遍历5次后，每个训练样本都可得到其输出结果作为第二层模型的输入\n",
    "\n",
    "(3) 对于测试集，每次训练出一个模型时，都用这个模型对其进行预测，则最终测试集的每个样本都会有5个输出结果，对这些结果取平均作为该样本的第二层输入\n",
    "\n",
    "除此之外，用 stacking 或者说 ensemble 这一类方法时还需要注意以下两点：\n",
    "\n",
    "Base Model 之间的相关性要尽可能的小，从而能够互补模型间的优势\n",
    "\n",
    "Base Model 之间的性能表现不能差距太大，太差的模型会拖后腿"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. common interface for K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/selectedFeatures/X_train_select.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-7e60183ef0fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_train_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./data/selectedFeatures/label.npy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx_test_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./data/selectedFeatures/X_test_select.npy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/tensorflow/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/selectedFeatures/X_train_select.npy'"
     ]
    }
   ],
   "source": [
    "# load train data and test data as ndarray\n",
    "# a m×n ndarray means that there are m samples， while each sample has n dimension feature\n",
    "x_train_file = './data/selectedFeatures/X_train_select.npy'\n",
    "y_train_file = './data/selectedFeatures/label.npy'\n",
    "x_test_file = './data/selectedFeatures/X_test_select.npy'\n",
    "x_train = np.load(x_train_file).astype(np.float)\n",
    "y_train = np.load(y_train_file).astype(np.float)\n",
    "x_test = np.load(x_test_file).astype(np.float)\n",
    "print(x_train.shape, y_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicModel(object):\n",
    "    \"\"\"Parent class of basic models\"\"\"\n",
    "    def train(self, x_train, y_train, x_val, y_val):\n",
    "        \"\"\"return a trained model and eval metric of validation data\"\"\"\n",
    "        pass\n",
    "\n",
    "    def predict(self, model, x_test):\n",
    "        \"\"\"return the predicted result\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def get_oof(self, x_train, y_train, x_test, n_folds = 5):\n",
    "        \"\"\"K-fold stacking\"\"\"\n",
    "        num_train, num_test = x_train.shape[0], x_test.shape[0]\n",
    "        oof_train = np.zeros((num_train,))\n",
    "        oof_test = np.zeros((num_test,))\n",
    "        oof_test_all_fold = np.zeros((num_test, n_folds))\n",
    "        aucs = []\n",
    "        KF = KFold(n_splits = n_folds, random_state=2017)\n",
    "        for i, (train_index, val_index) in enumerate(KF.split(x_train)):\n",
    "            print('{0} fold, train {1}, val {2}'.format(i, len(train_index), len(val_index)))\n",
    "            x_tra, y_tra = x_train[train_index], y_train[train_index]\n",
    "            x_val, y_val = x_train[val_index], y_train[val_index]\n",
    "            model, auc = self.train(x_tra, y_tra, x_val, y_val)\n",
    "            aucs.append(auc)\n",
    "            oof_train[val_index] = self.predict(model, x_val)\n",
    "            oof_test_all_fold[:, i] = self.predict(model, x_test)\n",
    "        oof_test = np.mean(oof_test_all_fold, axis=1)\n",
    "        print('all aucs {0}, average {1}'.format(aucs, np.mean(aucs)))\n",
    "        return oof_train, oof_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create two models for first-layer stacking: xgb and lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "class XGBClassifier(BasicModel):\n",
    "    def __init__(self):\n",
    "        \"\"\"set parameter\"\"\"\n",
    "        self.num_rounds=1000\n",
    "        self.early_stopping_round = 15\n",
    "        self.params = {\n",
    "            'objective': 'binary:logistic',\n",
    "            'eta': 0.1,\n",
    "            'max_depth': 8,\n",
    "            'eval_metric': 'auc',\n",
    "            'seed': 0,\n",
    "            'silent': 0\n",
    "        }\n",
    "        \n",
    "    def train(self, x_train, y_train, x_val, y_val):\n",
    "        print('train with xgb model')\n",
    "        xgbtrain = xgb.DMatrix(x_train, y_train)\n",
    "        xgbval = xgb.DMatrix(x_val, y_val)\n",
    "        watchlist = [(xgbtrain, 'train'), (xgbval, 'val')]\n",
    "        model = xgb.train(self.params,\n",
    "                          xgbtrain,\n",
    "                          self.num_rounds,\n",
    "                          watchlist,\n",
    "                          early_stopping_rounds = self.early_stopping_rounds)\n",
    "        return model, float(model.eval(xgbval).split()[1].split(':')[1])\n",
    "    \n",
    "    def predict(self, model, x_test):\n",
    "        print('test with xgb model')\n",
    "        xgbtest = xgb.DMatrix(x_test)\n",
    "        return model.predict(xgbtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "class LGBClassifier(BasicModel):\n",
    "    def __init__(self):\n",
    "        self.num_boost_round = 2000\n",
    "        self.early_stopping_round = 15\n",
    "        self.params = {\n",
    "            'task': 'train',\n",
    "            'boosting_type': 'dart',\n",
    "            'objective': 'binary',\n",
    "            'metric': {'auc', 'binary_logloss'},\n",
    "            'num_leaves': 80,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.5,\n",
    "            'bagging_fraction': 1,\n",
    "            'bagging_freq': 5,\n",
    "            'max_bin': 300,\n",
    "            'is_unbalance': True,\n",
    "            'lambda_l2': 50,\n",
    "            'verbose': -1\n",
    "        }\n",
    "    \n",
    "    def train(self, x_train, y_train, x_val, y_val):\n",
    "        print('train with lgb model')\n",
    "        lgbtrain = lgb.Dataset(x_train, y_train)\n",
    "        lgbval = lgb.Dataset(x_val, y_val)\n",
    "        model = lgb.train(self.params,\n",
    "                         lgbtrain,\n",
    "                         valid_sets=lgbval,\n",
    "                         verbose_eval=self.num_boost_round,\n",
    "                         num_boost_round=self.num_boost_round,\n",
    "                         early_stopping_rounds=self.early_stopping_rounds)\n",
    "        return model, model.best_score['valid_0']['auc']\n",
    "    \n",
    "    def predict(self, model, x_test):\n",
    "        print('test with lgb model')\n",
    "        return model.predict(x_test, num_iteration=model.best_iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下一个步骤就是将这两个基模型的输出作为第二层模型的输入，这里选用的第二层模型是 LogisticsRegression，\n",
    "\n",
    "首先需要将各个基模型的输出 reshape 和 concatenate 成合适的大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-d0a5499d4317>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get output of first layer models and construct as input for the second layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlgb_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlgb_oof_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlgb_off_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_oof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlgb_oof_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlgb_oof_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "# get output of first layer models and construct as input for the second layer\n",
    "lgb_classifier = LGBClassifier()\n",
    "lgb_oof_train, lgb_off_test = lgb_classifier.get_oof(x_train, y_train, x_test)\n",
    "print(lgb_oof_train.shape, lgb_oof_test.shape)\n",
    "\n",
    "xgb_classifier = XGBClassifier()\n",
    "xgb_oof_train, xgb_oof_test = xgb_classifier.get_oof(x_train, y_train, x_test)\n",
    "print(xgb_oof_train.shape, xgb_oof_test.shape)\n",
    "\n",
    "input_train = [xgb_oof_train, lgb_oof_train]\n",
    "input_test = [xgb_oof_test, lgb_oof_test]\n",
    "\n",
    "stacked_train = np.concatenate([f.reshape(-1, 1) for f in input_train], axis=1)\n",
    "stacked_test = np.concatenate([f.reshape(-1, 1) for f in input_test], axis=1)\n",
    "print(stacked_train.shape, stacked_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stacked_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-71eb20cbf0b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# split for validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstacked_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mx_tra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstacked_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstacked_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stacked_train' is not defined"
     ]
    }
   ],
   "source": [
    "# use LR as the model of the second layer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "# split for validation\n",
    "n = int(stacked_train.shape[0] * 0.8)\n",
    "x_tra, y_tra = stacked_train[:n], y_train[:n]\n",
    "x_val, y_val = stacked_train[n:], y_train[n:]\n",
    "model = LinearRegression()\n",
    "model.fit(x_tra,y_tra)\n",
    "y_pred = model.predict(x_val)\n",
    "print(metrics.roc_auc_score(y_val, y_pred))\n",
    "\n",
    "# predict on test data\n",
    "final_model = LinearRegression()\n",
    "final_model.fit(stacked_train, y_train)\n",
    "test_prediction = final_model.predict(stacked_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
